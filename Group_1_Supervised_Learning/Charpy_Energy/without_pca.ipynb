{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4b7d7b3",
   "metadata": {},
   "source": [
    "# Model Training for Charpy Energy Prediction without using PCA Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50db35a8",
   "metadata": {},
   "source": [
    "We are going to train and compare several regression models using the original Charpy energy dataset, without applying Principal Component Analysis (PCA) for dimensionality reduction. The objective is to evaluate model performance directly on the raw input features and determine whether using untransformed data provides better predictive accuracy. Charpy Energy (in joules) represents the toughness of welded materials‚Äîthe energy absorbed during fracture under impact‚Äîand serves as a key indicator of mechanical strength and ductility. Various models, including Linear Regression, Ridge, Lasso, ElasticNet, Decision Tree, Random Forest, Gradient Boosting, and SVR, will be trained and optimized using 5-fold cross-validation with GridSearchCV. Model performance will be evaluated through R¬≤, MAE, and RMSE metrics, complemented by an overfitting analysis to identify the most robust model for predicting Charpy impact energy from real-world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc05a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "import joblib\n",
    "import os \n",
    "from sklearn.metrics import mean_squared_error, r2_score , mean_absolute_error\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92b645f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('trained_models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ce48ba61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1652, 52)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../welddatabase/welddb_new.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af0874a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1321\n",
      "Testing samples: 331\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('Charpy_Energy_J', axis=1)\n",
    "y = df['Charpy_Energy_J']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "632ab589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Lignes conserv√©es apr√®s suppression des NaN dans la cible : 879 / 1652\n",
      "‚úÖ Lignes restantes apr√®s filtrage : 879\n",
      "üìä Colonnes num√©riques : 51\n",
      "‚úÖ Imputation r√©ussie. Dimensions finales : (879, 50)\n",
      "Nombre total de valeurs manquantes restantes : 0\n",
      "Nombre de NaN dans y : 0\n"
     ]
    }
   ],
   "source": [
    "# --- 1Ô∏è‚É£ Supprimer les lignes dont la cible est manquante ---\n",
    "df_clean = df.dropna(subset=['Charpy_Energy_J'])\n",
    "print(f\"‚úÖ Lignes conserv√©es apr√®s suppression des NaN dans la cible : {len(df_clean)} / {len(df)}\")\n",
    "\n",
    "# --- 2Ô∏è‚É£ Supprimer les lignes trop incompl√®tes ---\n",
    "df_filtered = df_clean[df_clean.isnull().mean(axis=1) < 0.5]\n",
    "print(f\"‚úÖ Lignes restantes apr√®s filtrage : {len(df_filtered)}\")\n",
    "\n",
    "# --- 3Ô∏è‚É£ S√©parer X et y ---\n",
    "X = df_filtered.drop(columns=['Charpy_Energy_J'])\n",
    "y = df_filtered['Charpy_Energy_J']\n",
    "\n",
    "# --- 4Ô∏è‚É£ S√©parer les colonnes num√©riques ---\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"üìä Colonnes num√©riques : {len(numeric_cols)}\")\n",
    "\n",
    "# --- 5Ô∏è‚É£ Appliquer KNNImputer uniquement sur ces colonnes ---\n",
    "imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "X_num_imputed = imputer.fit_transform(X[numeric_cols])\n",
    "\n",
    "# --- 6Ô∏è‚É£ Corriger automatiquement la coh√©rence de taille ---\n",
    "valid_col_count = X_num_imputed.shape[1]\n",
    "numeric_cols = numeric_cols[:valid_col_count]  # Ajuste si une colonne a √©t√© ignor√©e\n",
    "\n",
    "# --- 7Ô∏è‚É£ Reconstruction DataFrame coh√©rent ---\n",
    "X_imputed = pd.DataFrame(X_num_imputed, columns=numeric_cols, index=X.index)\n",
    "\n",
    "print(f\"‚úÖ Imputation r√©ussie. Dimensions finales : {X_imputed.shape}\")\n",
    "print(f\"Nombre total de valeurs manquantes restantes : {X_imputed.isna().sum().sum()}\")\n",
    "print(f\"Nombre de NaN dans y : {y.isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ad8c5d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Train set: 703 samples, Test set: 176 samples\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imputed, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"üìä Train set: {X_train.shape[0]} samples, Test set: {X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bb0a0d",
   "metadata": {},
   "source": [
    "# Defining the models and their Hyperparameter grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "03732fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define all regression models ---\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RidgeRegression': Ridge(),\n",
    "    'LassoRegression': Lasso(),\n",
    "    'ElasticNetRegression': ElasticNet(),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(random_state=42),\n",
    "    'RandomForestRegressor': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    'SVR': SVR()\n",
    "  \n",
    "}\n",
    "\n",
    "# --- Define the hyperparameter grids for each model ---\n",
    "param_grids = {\n",
    "    'LinearRegression': {},  # No hyperparameters to tune\n",
    "    'RidgeRegression': {'alpha': [0.1, 1.0, 10.0, 100.0]},\n",
    "    'LassoRegression': {'alpha': [0.1, 1.0, 10.0, 100.0]},\n",
    "    'ElasticNetRegression': {'alpha': [0.1, 1.0, 10.0], 'l1_ratio': [0.2, 0.5, 0.8]},\n",
    "    'DecisionTreeRegressor': {'max_depth': [5, 10, 20, None], 'min_samples_split': [2, 10, 20]},\n",
    "    'RandomForestRegressor': {'n_estimators': [100, 200], 'max_depth': [10, 20, None]},\n",
    "    'GradientBoostingRegressor': {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 10]},\n",
    "    'SVR': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca03bb",
   "metadata": {},
   "source": [
    "Model Training and Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c2ec7f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Training LinearRegression...\n",
      "‚úÖ Best Parameters: {}\n",
      "CV R¬≤: 0.5168 | Train R¬≤: 0.6324 | Test R¬≤: 0.5957\n",
      "MAE: 26.3282 | RMSE: 33.5351\n",
      "üìÅ Model saved as: trained_models/LinearRegression_without_PCA_model.pkl\n",
      "\n",
      "üöÄ Training RidgeRegression...\n",
      "‚úÖ Best Parameters: {'alpha': 0.1}\n",
      "CV R¬≤: 0.5175 | Train R¬≤: 0.6181 | Test R¬≤: 0.6003\n",
      "MAE: 26.4690 | RMSE: 33.3459\n",
      "üìÅ Model saved as: trained_models/RidgeRegression_without_PCA_model.pkl\n",
      "\n",
      "üöÄ Training LassoRegression...\n",
      "‚úÖ Best Parameters: {'alpha': 0.1}\n",
      "CV R¬≤: 0.5020 | Train R¬≤: 0.5926 | Test R¬≤: 0.6061\n",
      "MAE: 26.5304 | RMSE: 33.1038\n",
      "üìÅ Model saved as: trained_models/LassoRegression_without_PCA_model.pkl\n",
      "\n",
      "üöÄ Training ElasticNetRegression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.210e+05, tolerance: 1.716e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e+03, tolerance: 1.716e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Best Parameters: {'alpha': 0.1, 'l1_ratio': 0.8}\n",
      "CV R¬≤: 0.4837 | Train R¬≤: 0.5614 | Test R¬≤: 0.5895\n",
      "MAE: 27.2128 | RMSE: 33.7907\n",
      "üìÅ Model saved as: trained_models/ElasticNetRegression_without_PCA_model.pkl\n",
      "\n",
      "üöÄ Training DecisionTreeRegressor...\n",
      "‚úÖ Best Parameters: {'max_depth': 10, 'min_samples_split': 20}\n",
      "CV R¬≤: 0.5852 | Train R¬≤: 0.8635 | Test R¬≤: 0.5512\n",
      "MAE: 22.2042 | RMSE: 35.3319\n",
      "üìÅ Model saved as: trained_models/DecisionTreeRegressor_without_PCA_model.pkl\n",
      "\n",
      "üöÄ Training RandomForestRegressor...\n",
      "‚úÖ Best Parameters: {'max_depth': 20, 'n_estimators': 200}\n",
      "CV R¬≤: 0.7584 | Train R¬≤: 0.9699 | Test R¬≤: 0.8283\n",
      "MAE: 15.5922 | RMSE: 21.8531\n",
      "üìÅ Model saved as: trained_models/RandomForestRegressor_without_PCA_model.pkl\n",
      "\n",
      "üöÄ Training SVR...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 17\u001b[0m\n\u001b[0;32m      7\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m      8\u001b[0m     model,\n\u001b[0;32m      9\u001b[0m     param_grids[name],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# --- Train on the imputed dataset ---\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# --- Predictions on training and testing sets ---\u001b[39;00m\n\u001b[0;32m     20\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- 2Ô∏è‚É£ Model training and evaluation ---\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüöÄ Training {name}...\")\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        model,\n",
    "        param_grids[name],\n",
    "        cv=5,\n",
    "        scoring='r2',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # --- Train on the imputed dataset ---\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # --- Predictions on training and testing sets ---\n",
    "    y_train_pred = grid_search.predict(X_train)\n",
    "    y_test_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # --- Compute metrics ---\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "    # --- Store model results ---\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Best_Params': str(grid_search.best_params_),\n",
    "        'CV_R2': grid_search.best_score_,\n",
    "        'Train_R2': train_r2,\n",
    "        'Test_R2': test_r2,\n",
    "        'MAE_Test': test_mae,\n",
    "        'RMSE_Test': test_rmse\n",
    "    })\n",
    "\n",
    "    # --- Save the best model with clear naming ---\n",
    "    model_filename = f\"trained_models/{name}_without_PCA_model.pkl\"\n",
    "    joblib.dump(grid_search.best_estimator_, model_filename)\n",
    "\n",
    "    # --- Display quick summary ---\n",
    "    print(f\"‚úÖ Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"CV R¬≤: {grid_search.best_score_:.4f} | Train R¬≤: {train_r2:.4f} | Test R¬≤: {test_r2:.4f}\")\n",
    "    print(f\"MAE: {test_mae:.4f} | RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"üìÅ Model saved as: {model_filename}\")\n",
    "\n",
    "print(\"\\nüèÅ Training completed for all models (WITHOUT PCA)!\")\n",
    "\n",
    "# --- 3Ô∏è‚É£ Create and display organized results table ---\n",
    "results_df = pd.DataFrame(results).sort_values(by='Test_R2', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nüìä MODEL PERFORMANCE SUMMARY (WITHOUT PCA)\")\n",
    "print(\"=\" * 90)\n",
    "display(results_df.style.set_properties(**{\n",
    "    'background-color': '#1e1e1e',\n",
    "    'color': 'white',\n",
    "    'border-color': 'gray',\n",
    "    'text-align': 'center'\n",
    "}).format({\n",
    "    'CV_R2': \"{:.4f}\",\n",
    "    'Train_R2': \"{:.4f}\",\n",
    "    'Test_R2': \"{:.4f}\",\n",
    "    'MAE_Test': \"{:.4f}\",\n",
    "    'RMSE_Test': \"{:.4f}\"\n",
    "}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
